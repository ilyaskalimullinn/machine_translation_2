{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Translation using Transformer\n",
    "\n",
    "Небольшой пет-проект, представляющий собой модель машинного перевода с русского языка на английский с использованием архитектуры Transformer.\n",
    "\n",
    "Этот ноутбук посвящен обучению модели. Обязательно сначала посмотрите первый ноутбук — `1-data-analysis.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data\n",
    "\n",
    "Загрузим предобработанные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "import torch\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(palette='Set2')\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['src', 'trg'],\n",
       "        num_rows: 4334538\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['src', 'trg'],\n",
       "        num_rows: 240889\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['src', 'trg'],\n",
       "        num_rows: 240832\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_from_disk(\n",
    "    \"DATA/preprocessed-data\"\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tokenizers\n",
    "\n",
    "Достанем токенизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of src tokenizer: 36002\n",
      "Len of trg tokenizer: 30524\n"
     ]
    }
   ],
   "source": [
    "from util import get_tokenizers\n",
    "\n",
    "tokenizer_src, tokenizer_trg = get_tokenizers()\n",
    "\n",
    "print(f\"Len of src tokenizer: {len(tokenizer_src.vocab)}\")\n",
    "print(f\"Len of trg tokenizer: {len(tokenizer_trg.vocab)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "Итак, пару слов об архитектуре трансформер!\n",
    "\n",
    "Источники, опираясь на которые я реализовал эту архитектуру:\n",
    "- Основная статья — [Attention is All You Need](https://arxiv.org/pdf/1706.03762)\n",
    "- Статья о том, в какой последовательности применять `Layer Norm`, `Attention` и `FeedForward` — [On Layer Normalization in the Transformer Architecture](https://arxiv.org/pdf/2002.04745)\n",
    "- Гитхаб репозиторий, к которому я обращался, когда что-то улетало — [bentrevett](https://github.com/bentrevett/pytorch-seq2seq/tree/main)\n",
    "  \n",
    "Полностью расписывать то, как работает модель, я не стану, легче и понятнее будет прочитать статью. Далее можно почитать документацию к модулям, там я тоже довольно подробно объяснял, как что работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Num params: 35942204\n"
     ]
    }
   ],
   "source": [
    "d_model = 256\n",
    "num_heads = 8\n",
    "d_k = d_model\n",
    "d_v = d_model\n",
    "n_layers_encoder = 6\n",
    "n_layers_decoder = 6\n",
    "src_vocab_size = len(tokenizer_src.vocab)\n",
    "trg_vocab_size = len(tokenizer_trg.vocab)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pad_ind_src = tokenizer_src.pad_token_id\n",
    "pad_ind_trg = tokenizer_trg.pad_token_id\n",
    "bos_ind = tokenizer_trg.bos_token_id\n",
    "eos_ind = tokenizer_trg.eos_token_id\n",
    "d_ff = 4 * d_model\n",
    "p_dropout = 0.1\n",
    "max_length = 50\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "model = Transformer(\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    d_k=d_k,\n",
    "    d_v=d_v,\n",
    "    n_layers_encoder=n_layers_encoder,\n",
    "    n_layers_decoder=n_layers_decoder,\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    trg_vocab_size=trg_vocab_size,\n",
    "    device=device,\n",
    "    pad_ind_src=pad_ind_src,\n",
    "    pad_ind_trg=pad_ind_trg,\n",
    "    bos_ind=bos_ind,\n",
    "    eos_ind=eos_ind,\n",
    "    d_ff=d_ff,\n",
    "    p_dropout=p_dropout,\n",
    "    max_length=max_length,\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Num params: {sum(param.numel() for param in model.parameters() if param.requires_grad)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно иницилизировать веса модели. Наиболее часто в трансформерах применяется [инициализация Ксавье](https://paperswithcode.com/method/xavier-initialization#:~:text=Xavier%20Initialization%2C%20or%20Glorot%20Initialization,a%20n%20o%20u%20t%20%5D) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(36002, 256)\n",
       "    (positional_encoding): Embedding(50, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (layer_norm_attention): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mha): MultiHeadAttention(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (softmax): Softmax(dim=3)\n",
       "        )\n",
       "        (layer_norm_ff): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout_attention): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_ff): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(30524, 256)\n",
       "    (positional_encoding): Embedding(50, 256)\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderLayer(\n",
       "        (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm_3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (masked_mha): MultiHeadAttention(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (softmax): Softmax(dim=3)\n",
       "        )\n",
       "        (mha_encoder): MultiHeadAttention(\n",
       "          (fc_q): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_k): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_v): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (fc_o): Linear(in_features=256, out_features=256, bias=False)\n",
       "          (softmax): Softmax(dim=3)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (fc_1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (fc_2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "        (dropout_1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout_3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc): Linear(in_features=256, out_features=30524, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from util import xavier_init, set_seed\n",
    "\n",
    "set_seed(RANDOM_SEED)\n",
    "model.apply(xavier_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DataLoaders\n",
    "\n",
    "Для того, чтобы передать данные в модель, нам нужен специальный объект — DataLoader. Он соберет мини-батч из нескольких элементов (в нашем случае из 64), в котором с помощью токенизаторов создаст тензоры для `src` и `trg`, а также маски для них — `src_mask` и `trg_mask`. Логику создания DataLoader для всех трех датасетов (`train`, `valid` и `test`) я вынес в `util`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import get_dataloaders_lazy\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_lazy(\n",
    "    dataset, batch_size, tokenizer_src, tokenizer_trg\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Translator class\n",
    "\n",
    "Специальный класс, который мы будем использовать для удобства — `Translator`. Он принимает в себя нашу модель и токенизаторы и позволяет с помощью удобного интерфейса переводить строку с одного языка на другой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import Translator\n",
    "\n",
    "translator = Translator(model, tokenizer_src, tokenizer_trg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training\n",
    "\n",
    "Итак, пришло время обучить модель! Для этого я написал функцию `train`, в которой происходит много всего:\n",
    "1. Если уже есть сохраненная модель, то мы достанем ее параметры\n",
    "2. Проведем тренировочный цикл по одной эпохе\n",
    "3. Посчитаем метрики модели на валидационной выборке\n",
    "4. Сделаем шаг планировщика (`scheduler`)\n",
    "5. Визуализируем loss и метрику (в данном случае практически одно и то же, т.к. используем cross entropy и perplexity)\n",
    "6. Приведем примеры перевода\n",
    "7. Сохраним состояние модели + сохраним ее дополнительно как лучшую, если она получила лучшее значение метрики на валидационной выборке\n",
    "\n",
    "Обучаться будем на Cross Entropy Loss, предсказывая следующий токен:\n",
    "- Encoder получает на вход всю исходную последовательность (source), которую мы маскируем для того, чтобы модель не считала attention по padding токенам\n",
    "- Decoder получает целевую последовательность (target) и предсказывает для каждого токена следующий токен, основываясь на всей исходной последовательности (из Encoder) и на предшествующих токенах target'а (этого добиваемся с помощью маскирования)\n",
    "- В конце модель выдает распределение вероятностей (логиты) на каждый токен для каждого токена в каждой последовательности\n",
    "\n",
    "Значения гиперпараметров (dropout, learning rate, lr scheduler и label smoothing) я выбирал, основываясь на статьях, которые упомянул выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbdcbe2e7a84fb686ba6bf8fa53074a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training, epoch 1/20:   0%|          | 0/67728 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mlr_scheduler\u001b[38;5;241m.\u001b[39mStepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39mSTEP_SIZE, gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\n\u001b[1;32m      9\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39mpad_ind_trg, label_smoothing\u001b[38;5;241m=\u001b[39mLABEL_SMOOTHING)\n\u001b[0;32m---> 11\u001b[0m train(\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m     14\u001b[0m     scheduler\u001b[38;5;241m=\u001b[39mscheduler,\n\u001b[1;32m     15\u001b[0m     criterion\u001b[38;5;241m=\u001b[39mcriterion,\n\u001b[1;32m     16\u001b[0m     num_epochs\u001b[38;5;241m=\u001b[39mN_EPOCHS,\n\u001b[1;32m     17\u001b[0m     train_loader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[1;32m     18\u001b[0m     val_loader\u001b[38;5;241m=\u001b[39mvalid_loader,\n\u001b[1;32m     19\u001b[0m     clip_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     20\u001b[0m     path_to_save\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA/model-data/training.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m     path_to_save_best\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDATA/model-data/best.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     22\u001b[0m     loss_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCross Entropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m     metric_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPerplexity\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m     translator\u001b[38;5;241m=\u001b[39mtranslator,\n\u001b[1;32m     25\u001b[0m     examples_to_translate\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mкошки и собаки довольно крутые\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     26\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/study/ml/machine_translation_2/train.py:154\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, scheduler, num_epochs, train_loader, val_loader, clip_grad, path_to_save, path_to_save_best, loss_label, metric_label, translator, examples_to_translate)\u001b[0m\n\u001b[1;32m    152\u001b[0m device \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(last_epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 154\u001b[0m     loss_value, metric_value \u001b[38;5;241m=\u001b[39m train_epoch(\n\u001b[1;32m    155\u001b[0m         train_loader,\n\u001b[1;32m    156\u001b[0m         epoch,\n\u001b[1;32m    157\u001b[0m         num_epochs,\n\u001b[1;32m    158\u001b[0m         model,\n\u001b[1;32m    159\u001b[0m         optimizer,\n\u001b[1;32m    160\u001b[0m         criterion,\n\u001b[1;32m    161\u001b[0m         device,\n\u001b[1;32m    162\u001b[0m         clip_grad\u001b[38;5;241m=\u001b[39mclip_grad,\n\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(loss_value)\n\u001b[1;32m    165\u001b[0m     train_metric\u001b[38;5;241m.\u001b[39mappend(metric_value)\n",
      "File \u001b[0;32m~/Documents/study/ml/machine_translation_2/train.py:40\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(train_loader, epoch, num_epochs, model, optimizer, criterion, device, clip_grad)\u001b[0m\n\u001b[1;32m     37\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(src, trg, src_mask, trg_mask)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# (B, T, vocab_size), predictions for every token\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m pred \u001b[38;5;241m=\u001b[39m model(src, trg, src_mask, trg_mask)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# (B, vocab_size, T - 1), predictions for every token except for last\u001b[39;00m\n\u001b[1;32m     43\u001b[0m pred \u001b[38;5;241m=\u001b[39m pred[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/study/ml/machine_translation_2/model.py:717\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, trg, src_mask, trg_mask)\u001b[0m\n\u001b[1;32m    713\u001b[0m encoder_output_norm \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_layer_norm(encoder_output)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# (B, T, trg_vocab_size)\u001b[39;00m\n\u001b[1;32m    716\u001b[0m decoder_output, decoder_self_attention, decoder_encoder_attention \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 717\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(trg, encoder_output_norm, src_mask, trg_mask)\n\u001b[1;32m    718\u001b[0m )\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m decoder_output\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/study/ml/machine_translation_2/model.py:581\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, encoder_output_norm, src_mask, trg_mask)\u001b[0m\n\u001b[1;32m    578\u001b[0m pos_encoding \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(T)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(x\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# (1, T, d_model)\u001b[39;00m\n\u001b[0;32m--> 581\u001b[0m pos_encoding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositional_encoding(pos_encoding)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# (B, T, d_model)\u001b[39;00m\n\u001b[1;32m    584\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x \u001b[38;5;241m+\u001b[39m pos_encoding)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 5e-4\n",
    "STEP_SIZE = 5\n",
    "N_EPOCHS = 20\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_ind_trg, label_smoothing=LABEL_SMOOTHING)\n",
    "\n",
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    criterion=criterion,\n",
    "    num_epochs=N_EPOCHS,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=valid_loader,\n",
    "    clip_grad=1,\n",
    "    path_to_save=\"DATA/model-data/training.pt\",\n",
    "    path_to_save_best=\"DATA/model-data/best.pt\",\n",
    "    loss_label=\"Cross Entropy\",\n",
    "    metric_label=\"Perplexity\",\n",
    "    translator=translator,\n",
    "    examples_to_translate=[\"кошки и собаки довольно крутые\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
